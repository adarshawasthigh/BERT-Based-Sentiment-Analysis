# -*- coding: utf-8 -*-
"""Copy of Sentiment_Analysis_with_BERT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yVCJKT4Hw0HITCTF0u8pBBQcIdTqA6WK
"""

!pip install transformers datasets torch scikit-learn accelerate

import torch
from datasets import load_dataset
from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments

# 1. Load & Tokenize (Same as before)
dataset = load_dataset("imdb")
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')

def tokenize_function(examples):
    return tokenizer(examples['text'], padding="max_length", truncation=True, max_length=128)

tokenized_datasets = dataset.map(tokenize_function, batched=True)

# PyTorch specific: Remove text column and rename label
tokenized_datasets = tokenized_datasets.remove_columns(["text"])
tokenized_datasets = tokenized_datasets.rename_column("label", "labels")
tokenized_datasets.set_format("torch")

# Split for speed (optional)
train_dataset = tokenized_datasets["train"].shuffle(seed=42)
test_dataset = tokenized_datasets["test"].shuffle(seed=42)

model = BertForSequenceClassification.from_pretrained(
    'bert-base-uncased',
    num_labels=2
)

from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score

def compute_metrics(pred):
    labels = pred.label_ids
    preds = pred.predictions.argmax(-1)

    # Calculate all major metrics
    precision = precision_score(labels, preds)
    recall = recall_score(labels, preds)
    f1 = f1_score(labels, preds)
    acc = accuracy_score(labels, preds)

    return {
        'accuracy': acc,
        'f1': f1,
        'precision': precision,
        'recall': recall
    }
from transformers import EarlyStoppingCallback

# 1. Update TrainingArguments
training_args = TrainingArguments(
    output_dir='./results_early_stopping',
    num_train_epochs=5,              # Set this high; the callback will stop it early
    eval_strategy="epoch",           # Must evaluate to check if loss is improving
    save_strategy="epoch",           # Must save to allow loading the best model
    load_best_model_at_end=True,     # Required for EarlyStopping
    metric_for_best_model="loss",    # Stop based on Validation Loss
    greater_is_better=False,         # Lower loss is better
    # ... rest of your arguments
)

# 2. Add the Callback to the Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=test_dataset,
    compute_metrics=compute_metrics,
    callbacks=[EarlyStoppingCallback(early_stopping_patience=1)] # Stop after 1 epoch of no improvement
)

trainer.train()

import torch
from transformers import BertTokenizer, BertForSequenceClassification

# 1. Setup Device (GPU if available, else CPU)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# 2. Load the Model and Tokenizer
# If you just finished training, the model is already in memory as 'model'.
# If you are restarting, load from your output directory:
model_path = "./results/checkpoint-375"  # Replace with your actual checkpoint folder
# model = BertForSequenceClassification.from_pretrained(model_path)
# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')

model.to(device)
model.eval() # Set to evaluation mode (turns off Dropout)

# 3. Define the Predict Function
def predict_sentiment(text):
    # Prepare the text
    inputs = tokenizer(
        text,
        padding=True,
        truncation=True,
        max_length=128,
        return_tensors="pt"
    ).to(device)

    # Get predictions
    with torch.no_grad():
        outputs = model(**inputs)

    # Apply Softmax to get probabilities
    probs = torch.nn.functional.softmax(outputs.logits, dim=-1)

    # Get the highest probability class
    pred_label = torch.argmax(probs, dim=-1).item()
    confidence = probs[0][pred_label].item()

    # Map to label
    label_map = {0: "NEGATIVE", 1: "POSITIVE"}

    return label_map[pred_label], confidence

# ---------------------------------------------------------
# 4. Test it out!
# ---------------------------------------------------------

# Example 1: Clear Positive
review1 = "The cinematography was breathtaking and the plot kept me on the edge of my seat."
label, score = predict_sentiment(review1)
print(f"Review: '{review1}'")
print(f"Sentiment: {label} ({score:.2%})\n")

# Example 2: Clear Negative
review2 = "I wasted two hours of my life. The acting was wooden and the script made no sense."
label, score = predict_sentiment(review2)
print(f"Review: '{review2}'")
print(f"Sentiment: {label} ({score:.2%})\n")

# Example 3: Tricky / Sarcastic (BERT usually gets this right!)
review3 = "This is a Great movie if you enjoy watching paint dry."
label, score = predict_sentiment(review3)
print(f"Review: '{review3}'")
print(f"Sentiment: {label} ({score:.2%})")

review4 = "I have seen all 3 parts of masti and thought this might also land some jokes which i can laugh with.But this time i didnt laugh for even 1 joke i feel like vomiting after watching this movie .Seriously why even they made this movie. Each the songs are not good this time. Overall rating for movie :-1/10."
label, score = predict_sentiment(review4)
print(f"Review: '{review4}'")
print(f"Sentiment: {label} ({score:.2%})")

import shutil
from google.colab import files

# 1. Save the model and tokenizer to a folder
output_folder = "bert_imdb_model"
model.save_pretrained(output_folder)
tokenizer.save_pretrained(output_folder)

# 2. Zip the folder (easier to download one file than many)
shutil.make_archive("bert_imdb_model_zipped", 'zip', output_folder)

# 3. Trigger the download to your local machine
files.download("bert_imdb_model_zipped.zip")

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, precision_recall_curve, auc

# ---------------------------------------------------------
# 1. Get Predictions
# ---------------------------------------------------------
print("Generating predictions...")
predictions = trainer.predict(test_dataset)
preds = np.argmax(predictions.predictions, axis=-1)   # Convert logits to class IDs (0 or 1)
labels = predictions.label_ids                        # Actual True Labels
probs = torch.nn.functional.softmax(torch.tensor(predictions.predictions), dim=-1)[:, 1] # Probabilities for Positive class

# ---------------------------------------------------------
# 2. Setup Plots
# ---------------------------------------------------------
fig, ax = plt.subplots(1, 2, figsize=(16, 6))

# ---------------------------------------------------------
# Plot A: Confusion Matrix
# ---------------------------------------------------------
cm = confusion_matrix(labels, preds)

# Create heatmap
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax[0],
            xticklabels=['Negative', 'Positive'],
            yticklabels=['Negative', 'Positive'])

ax[0].set_xlabel('Predicted Label', fontsize=12)
ax[0].set_ylabel('True Label', fontsize=12)
ax[0].set_title('Confusion Matrix', fontsize=14)

# ---------------------------------------------------------
# Plot B: Precision-Recall Curve
# ---------------------------------------------------------
precision, recall, _ = precision_recall_curve(labels, probs)
pr_auc = auc(recall, precision)

ax[1].plot(recall, precision, label=f'BERT (AUC = {pr_auc:.2f})', color='darkorange', lw=2)
ax[1].set_xlabel('Recall (Sensitivity)', fontsize=12)
ax[1].set_ylabel('Precision', fontsize=12)
ax[1].set_title('Precision-Recall Curve', fontsize=14)
ax[1].legend(loc='lower left')
ax[1].grid(True, linestyle='--', alpha=0.6)

plt.tight_layout()
plt.show()

